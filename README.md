# **Projet ETL - Gestion des Donn√©es de V√©los en Libre-Service** üö≤

Ce projet propose un pipeline ETL complet pour l'ingestion, la consolidation et l'agr√©gation des donn√©es de v√©los en libre-service dans plusieurs villes fran√ßaises : **Paris**, **Nantes**, et **Toulouse**. Il vise √† appliquer les concepts cl√©s de la data ing√©nierie enseign√©s au cours, en utilisant des technologies modernes comme **DuckDB**, **Pandas** et des **APIs Open Data**.

---

## **üéØ Objectifs du Projet**

- **Ingestion des Donn√©es :** Collecter les donn√©es open-source de Paris, Nantes et Toulouse.
- **Consolidation des Donn√©es :** Organiser et structurer les donn√©es dans une base DuckDB.
- **Enrichissement des Donn√©es :** Ajouter les informations officielles depuis l‚ÄôAPI gouvernementale "Open Data Communes".
- **Mod√©lisation Dimensionnelle :** Cr√©er un mod√®le pour faciliter l'analyse.
- **Agr√©gation des Donn√©es :** Produire des statistiques utiles sur la disponibilit√© des v√©los.

---

## **üìÅ Structure du Projet**

```
/src
    ‚îú‚îÄ‚îÄ data_agregation.py          # Agr√©gation des donn√©es
    ‚îú‚îÄ‚îÄ data_consolidation.py       # Consolidation et stockage des donn√©es
    ‚îú‚îÄ‚îÄ data_ingestion.py           # R√©cup√©ration des donn√©es API
    ‚îî‚îÄ‚îÄ main.py                     # Script principal ETL
/data
    ‚îú‚îÄ‚îÄ raw_data/                   # Fichiers JSON r√©cup√©r√©s
    ‚îú‚îÄ‚îÄ duckdb/                     # Base de donn√©es DuckDB
    ‚îÇ   ‚îî‚îÄ‚îÄ mobility_analysis.duckdb
/sql_statements
    ‚îú‚îÄ‚îÄ create_agregate_tables.sql  # Script SQL pour cr√©er les tables d'agr√©gation
    ‚îî‚îÄ‚îÄ create_consolidate_tables.sql # Script SQL pour cr√©er les tables de consolidation
.venv/                              # Environnement virtuel Python
.gitignore                          # Fichiers ignor√©s par Git
requirements.txt                    # D√©pendances Python
README.md                           # Documentation
```

---

## **üîÑ Pipeline ETL : √âtapes du Processus**

### **1. Ingestion des Donn√©es** üóÇÔ∏è

Les fichiers JSON sont collect√©s via des **APIs Open Data**. Chaque fonction d‚Äôingestion t√©l√©charge les donn√©es et les stocke localement avec une structure organis√©e par date. 

**Fonctions principales :**
- `get_paris_realtime_bicycle_data()`
- `get_nantes_realtime_bicycle_data()`
- `get_toulouse_realtime_bicycle_data()`
- `get_commune_data()`

---

### **2. Consolidation des Donn√©es** üìä

Les donn√©es JSON sont transform√©es et ins√©r√©es dans **DuckDB** √† l'aide de Pandas. Chaque ville est trait√©e ind√©pendamment pour tenir compte des sp√©cificit√©s de leurs APIs respectives.

**Difficult√©s rencontr√©es :**
- **Formats Incoh√©rents :** Les colonnes entre les diff√©rentes APIs (Paris, Nantes, Toulouse) ont d√ª √™tre harmonis√©es.
- **Absence de Codes INSEE :** Les donn√©es brutes des villes de Nantes et Toulouse ne contenaient pas de code INSEE, ce qui a n√©cessit√© l‚Äôenrichissement via l‚ÄôAPI des communes fran√ßaises.

**Exemple : Consolidation des Donn√©es des Villes**
```python
def consolidate_city_data():
    con = duckdb.connect(database="data/duckdb/mobility_analysis.duckdb", read_only=False)
    with open(f"data/raw_data/{date.today().strftime('%Y-%m-%d')}/commune_data.json", "r") as file:
        commune_data = json.load(file)
    commune_df = pd.DataFrame(commune_data)
    con.register('commune_df', commune_df)
    con.execute("INSERT OR REPLACE INTO CONSOLIDATE_CITY SELECT * FROM commune_df;")
```

---

### **3. Agr√©gation des Donn√©es** üìà

Une **mod√©lisation dimensionnelle** est mise en place avec trois tables principales :
- **DIM_CITY** : Informations sur les villes.
- **DIM_STATION** : Informations sur les stations.
- **FACT_STATION_STATEMENT** : Donn√©es sur les disponibilit√©s de v√©los en temps r√©el.

**Difficult√©s rencontr√©es :**
- **Jointures Incorrectes :** Les jointures SQL initiales sur les champs `CITY_CODE` et `STATION_ID` ont d√ª √™tre corrig√©es pour garantir l‚Äôint√©grit√© des donn√©es.

**Exemple d‚ÄôAgr√©gation :**
```python
def agregate_fact_station_statements():
    con = duckdb.connect(database="data/duckdb/mobility_analysis.duckdb", read_only=False)
    sql_statement = """
    INSERT OR REPLACE INTO FACT_STATION_STATEMENT
    SELECT
        CONSOLIDATE_STATION_STATEMENT.STATION_ID,
        CONSOLIDATE_STATION.CITY_CODE AS CITY_ID,
        CONSOLIDATE_STATION_STATEMENT.BICYCLE_DOCKS_AVAILABLE,
        CONSOLIDATE_STATION_STATEMENT.BICYCLE_AVAILABLE,
        CONSOLIDATE_STATION_STATEMENT.LAST_STATEMENT_DATE,
        CURRENT_DATE AS CREATED_DATE
    FROM CONSOLIDATE_STATION_STATEMENT
    JOIN CONSOLIDATE_STATION ON CONSOLIDATE_STATION.ID = CONSOLIDATE_STATION_STATEMENT.STATION_ID;
    """
    con.execute(sql_statement)
```

---

## **üöÄ Installation et Ex√©cution**

### **üõ†Ô∏è Pr√©-requis**
- **Python 3.9+**
- **Virtualenv** (optionnel)

### **üì¶ Installation**
```bash
git clone https://github.com/ayaelhaouitti/polytech-de-101-2024-tp-subject.git
cd polytech-de-101-2024-tp-subject
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

### **‚ñ∂Ô∏è Ex√©cution du Pipeline ETL**
```bash
python src/main.py
```

---

## **üìä Requ√™tes SQL Utiles**

### **1. Nombre d'emplacements disponibles de v√©los dans une ville**
```sql
-- Nb d'emplacements disponibles de v√©los dans une ville
SELECT dm.NAME, tmp.SUM_BICYCLE_DOCKS_AVAILABLE
FROM DIM_CITY dm INNER JOIN (
    SELECT CITY_ID, SUM(BICYCLE_DOCKS_AVAILABLE) AS SUM_BICYCLE_DOCKS_AVAILABLE
    FROM FACT_STATION_STATEMENT
    WHERE CREATED_DATE = (SELECT MAX(CREATED_DATE) FROM CONSOLIDATE_STATION)
    GROUP BY CITY_ID
) tmp ON dm.ID = tmp.CITY_ID
WHERE lower(dm.NAME) in ('paris', 'nantes', 'vincennes', 'toulouse');
```

### **2. Nombre de v√©los disponibles en moyenne dans chaque station**
```sql
-- Nb de v√©los disponibles en moyenne dans chaque station
SELECT ds.name, ds.code, ds.address, tmp.avg_dock_available
FROM DIM_STATION ds JOIN (
    SELECT station_id, AVG(BICYCLE_AVAILABLE) AS avg_dock_available
    FROM FACT_STATION_STATEMENT
    GROUP BY station_id
) AS tmp ON ds.id = tmp.station_id;
```

---

## **üìå Conclusion**

Le projet ETL permet de **centraliser, consolider et analyser** les donn√©es de v√©los en libre-service pour les villes de Paris, Nantes et Toulouse. Gr√¢ce √† son architecture modulaire, ce pipeline peut facilement int√©grer de nouvelles villes et s‚Äôadapter √† d'autres sources de donn√©es.

---

üíª **Auteurs :**  
- Aya Elhaouitti  
- Cl√©ment Fortin